{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Oqd4y5orF8h"
   },
   "source": [
    "<img src=\"https://www.digitalhouse.com/logo-DH.png\" width=\"200\" height=\"100\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogFYft1srF8i"
   },
   "source": [
    "<h3><b>Curso:</b> Data Science / <b>Año:</b> 2020 / <b>Sede:</b> Casa</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5E3bYYforF8i"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dn7OMfFurF8j"
   },
   "source": [
    "<h3><b>TP Integrador:</b> Text Mining de <i>tweets</i> de anuncios del gobierno durante la cuarentena.</h3>\n",
    "<blockquote>\n",
    "        <ul>\n",
    "          <li><i>Sentiment analysis</i> de los comentarios de los usuarios.</li>\n",
    "          <li>Clustering de <i>tweets</i> de los usuarios.</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHhEZxazrF8j"
   },
   "source": [
    "<h3><b>Grupo 10:</b></h3>\n",
    "<blockquote>\n",
    "        <ul>\n",
    "          <li>Maria Eugenia Perotti</li>\n",
    "          <li>Gastón Ortíz</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwFwgRkxUEHs"
   },
   "source": [
    "# Sobre el trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2wWW-AuWEU-"
   },
   "source": [
    "Nuestra propuesta es realizar _text mining_ sobre tweets publicados durante la cuarentena, concentrándonos específicamente en las fechas en las que el presidente hace los anuncios relacionados al distanciamiento social preventivo y obligatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnaiD3eQi0Um"
   },
   "source": [
    "## Criterios de búsqueda.\n",
    "Debido al gran volumen de _tweets_ y a las limitaciones de la biblioteca que estamos utilizando, nos vimos forzados a limitar los criterios de búsqueda.\n",
    "\n",
    "<b><u>Ciudades:</u></b>\n",
    "* Buenos Aires\n",
    "* Cordoba\n",
    "* Rosario\n",
    "* Mendoza\n",
    "* Tucumán\n",
    "* San Juan\n",
    "* Neuquén\n",
    "* Paraná\n",
    "* Comodoro Rivadavia\n",
    "\n",
    "<b><u>Cuentas:</u></b>\n",
    "* Ministerio de Salud de la Nación | @msalnacion\n",
    "* Casa Rosada | @CasaRosada\n",
    "* Horacio Rodríguez Larreta | @horaciorlarreta\n",
    "* Alberto Fernández | @alferdez\n",
    "* Alberto Fernández Prensa | @alferdezprensa\n",
    "* Axel Kicillof | @Kicillofok\n",
    "* Cristina Kirchner | @CFKArgentina\n",
    "\n",
    "<b><u>Hashtags:</u></b>\n",
    "* #covid19\n",
    "* #covid\n",
    "* #coronavirus\n",
    "* #cuarentena\n",
    "* #albertofernandez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUNsCvDXi0Ub"
   },
   "source": [
    "# Preparación de libraries y funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se está trabajando localmente\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install GetOldTweets3\n",
    "    !pip install unidecode\n",
    "    ruta_drive = \"/content/drive/My Drive/TP Integrador/Notebooks/Data/\"\n",
    "except ModuleNotFoundError:    \n",
    "    print(\"Se está trabajando localmente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICL7gwGMTNCC"
   },
   "source": [
    "## Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "fia0GSZYi0Ub",
    "outputId": "def5a598-d364-43c3-b7da-5350021d0129"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "import datetime\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAyWm4ivi0Ue"
   },
   "source": [
    "## Definición de funciones.\n",
    "En esta sección definimos las funciones que vamos a utilizar en la notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kj-_OiT4i0Ue"
   },
   "source": [
    "### Función para obtener los tweets de acuerdo a los criterios de búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcWyWWM9i0Uf"
   },
   "outputs": [],
   "source": [
    "def get_tweets(list_criterios, fecha_inicio, fecha_final, maximo=250):\n",
    "    tweets_total = []\n",
    "    for criterio in list_criterios:\n",
    "        tweetCriteria = got.manager.TweetCriteria().setQuerySearch(criterio).setSince(fecha_inicio).setUntil(fecha_final).setMaxTweets(maximo)\n",
    "        tweets_total = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    return tweets_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZnaOCKRi0Uh"
   },
   "source": [
    "### Función para limpiar los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjyM3y-8i0Ui"
   },
   "outputs": [],
   "source": [
    "def limpiar(tweet_texto):\n",
    "    text = ' '.join(re.sub(r\"(@)|([^0-9A-Za-z \\t])|(www.[^ ]+)|(https?://[^ ]+)\", \"\", unidecode.unidecode(tweet_texto.lower())).split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbA9TFkqi0Uj"
   },
   "source": [
    "### Función para crear un dataframe en base a los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIJYgRcOi0Uk"
   },
   "outputs": [],
   "source": [
    "def create_df(tweets_anuncios):\n",
    "    datos = []\n",
    "    for anuncio in tweets_anuncios:\n",
    "        for ciudad in tweets_anuncios[anuncio]: \n",
    "            for tweet in tweets_anuncios[anuncio][ciudad]:\n",
    "                registro = {'username': tweet.username, 'tweet': limpiar(tweet.text), \\\n",
    "                            'fecha': tweet.date, 'anuncio':anuncio, 'ubicacion':ciudad, 'id':tweet.id}\n",
    "                datos.append(registro)\n",
    "    df = pd.DataFrame(data=datos)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para limpiar dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos listas de los usuarios y topics que vamos a eliminar\n",
    "usuarios_blacklist = ['sergistack', 'GamesRedDeer']\n",
    "usuarios_medios = ['gustavorearte1','gerdellamonica','radiofonica1007',' pmgcharly',' NTodxs',' Noticiasde_',' nora_verges',' mnspezzapria',' METRO_RADIO_TV',' MartinD50004804',' mariogaloppo',' LUIS20GEREZ',' losprimerostuc',' lacriticaok',' lacapital',' IldefonsoM',' HernanMundo',' elsolquilmes',' ellitoral',' cronica',' cordoba',' Contexto_Tuc',' ConLaGenteRos',' con_sello',' Cadena3Com',' AvellanedaReal',' AiredeSantaFe',' AgenciaDib',' Adry1BC',' ADNsur',' abccordoba',' 104Urbana']\n",
    "topicos_excluidos = ['pique','barcelona', 'bayern munich', 'barca', 'bayern', 'barsa', 'anabelle', 'annabell', 'annabelle', 'messi', 'balvin', 'pampita']\n",
    "\n",
    "def clean_up_df(df):\n",
    "    #definimos una máscara para excluir a los usuarios en la lista negra\n",
    "    mask_not_bl = [x not in usuarios_blacklist for x in df['username']] \n",
    "    df = df[mask_not_bl]\n",
    "    #definimos una máscara para excluir a los usuarios en la lista negra\n",
    "    mask_not_media = [x not in usuarios_medios for x in df['username']] \n",
    "    df = df[mask_not_media]\n",
    "    df.drop_duplicates(subset=['tweet'], keep=False, inplace=True)\n",
    "    # máscara de tópicos excluidos\n",
    "    mask_not_topics = [x not in topicos_excluidos for x in df['tweet']] \n",
    "    df = df[mask_not_topics]\n",
    "    \n",
    "    try:\n",
    "        df.drop(columns=['index'], axis=0, inplace=True)\n",
    "    except:\n",
    "        print(\"No existe la columna index\")\n",
    "        \n",
    "    try:\n",
    "        df.drop(columns=['fecha_sola'], axis=0, inplace=True)\n",
    "    except:\n",
    "        print(\"No existe la columna fecha_sola\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enORDGTgi0Um"
   },
   "source": [
    "# Obtención de tweets.\n",
    "En esta sección definimos los criterios de búsqueda y ejecutamos las funciones descritas previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llamado a la API para obtener los tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZWUIGfAi0Um"
   },
   "source": [
    "Procedemos a declarar los parámetros que utilizaremos para las búsquedas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKk6u9KZi0Un"
   },
   "outputs": [],
   "source": [
    "fecha_inicio = [\"2020-03-19T21:00:38Z\",\"2020-03-29T20:00:38Z\",\"2020-04-10T20:00:38Z\",\"2020-04-25T18:00:38Z\",\"2020-05-08T20:00:38Z\",\"2020-05-23T20:00:38Z\",\"2020-06-04T20:00:38Z\",\"2020-06-26T18:00:38Z\",\"2020-07-17T14:00:38Z\",\"2020-07-31T14:00:38Z\",\"2020-08-14T14:00:38Z\"]\n",
    "fecha_final =  [\"2020-03-20T04:00:38Z\",\"2020-03-30T04:00:38Z\",\"2020-04-11T04:00:38Z\",\"2020-04-26T04:00:38Z\",\"2020-05-09T04:00:38Z\",\"2020-05-24T04:00:38Z\",\"2020-06-05T04:00:38Z\",\"2020-06-27T04:00:38Z\",\"2020-07-18T04:00:38Z\",\"2020-08-01T04:00:38Z\",\"2020-08-15T04:00:38Z\"]\n",
    "criterios = [\"cuarentena\",\"msalnacion\",\"CasaRosada\",\"alferdez\", \"alferdezprensa\"]\n",
    "#ciudades = [\"Buenos Aires, Argentina\"],\"Cordoba, Argentina\",\"Rosario, Argentina\",\"Mendoza, Argentina\", \"Tucumán, Argentina\",\"Paraná, Argentina\"\n",
    "#ciudades = [\"Cordoba, Argentina\"]\n",
    "#ciudades = [\"Rosario, Argentina\"]\n",
    "#ciudades = [\"Mendoza, Argentina\"]\n",
    "ciudades = [\"Tucumán, Argentina\"]\n",
    "#ciudades = [\"Paraná, Argentina\"]\n",
    "#radio = \"200km\"\n",
    "maximo = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6haV4W_i0Uq"
   },
   "source": [
    "Ejecutamos la función para traer los tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Tf0DYBdCi0Uq",
    "outputId": "521d2884-83b5-423d-913a-03d5f6566d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
      "Try to open in browser: https://twitter.com/search?q=alferdez%20since%3A2020-07-31T14%3A00%3A38Z%20until%3A2020-08-01T04%3A00%3A38Z&src=typd\n",
      "9\n",
      "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
      "Try to open in browser: https://twitter.com/search?q=cuarentena%20since%3A2020-08-14T14%3A00%3A38Z%20until%3A2020-08-15T04%3A00%3A38Z&src=typd\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "dic_tweets = {}\n",
    "for i in range(len(fecha_inicio)):\n",
    "    dic_tweets[\"Anuncio_\"+str(i+1)] = {}\n",
    "    for ciudad in ciudades:\n",
    "        try:\n",
    "            dic_tweets[\"Anuncio_\"+str(i+1)][ciudad] = get_tweets(criterios,fecha_inicio[i],fecha_final[i],maximo)\n",
    "        except:\n",
    "            continue\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SokgvvPGi0Us"
   },
   "source": [
    "### Creación del dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GREyLQLi0Us"
   },
   "source": [
    "Ejecutamos la función para crear el dataframe y le pasamos como parámetros los tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxUAT6zsi0Us"
   },
   "outputs": [],
   "source": [
    "df = create_df(dic_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHyWvqGsi0Uu"
   },
   "source": [
    "Verificamos que haya creado exitosamente el dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "0dpWhoBwi0Uu",
    "outputId": "43e67e98-f46f-4b2f-d8d0-a447120fab84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GonzaloBuxo</td>\n",
       "      <td>apoyo total las medidas fuerza presidente esta...</td>\n",
       "      <td>2020-03-19 23:59:45+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Mendoza, Argentina</td>\n",
       "      <td>1240790092408672257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sergistack</td>\n",
       "      <td>usas google chrome lo siento por las mayuscula...</td>\n",
       "      <td>2020-03-28 20:07:18+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Mendoza, Argentina</td>\n",
       "      <td>1243993087531266049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gacela2019</td>\n",
       "      <td>asi lo hacemos sr presidente</td>\n",
       "      <td>2020-03-19 23:58:50+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Mendoza, Argentina</td>\n",
       "      <td>1240789862191685639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username                                              tweet  \\\n",
       "0  GonzaloBuxo  apoyo total las medidas fuerza presidente esta...   \n",
       "1   sergistack  usas google chrome lo siento por las mayuscula...   \n",
       "2   gacela2019                       asi lo hacemos sr presidente   \n",
       "\n",
       "                      fecha    anuncio           ubicacion  \\\n",
       "0 2020-03-19 23:59:45+00:00  Anuncio_1  Mendoza, Argentina   \n",
       "1 2020-03-28 20:07:18+00:00  Anuncio_1  Mendoza, Argentina   \n",
       "2 2020-03-19 23:58:50+00:00  Anuncio_1  Mendoza, Argentina   \n",
       "\n",
       "                    id  \n",
       "0  1240790092408672257  \n",
       "1  1243993087531266049  \n",
       "2  1240789862191685639  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2452, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t957SjbRi0VU"
   },
   "source": [
    "#### Creación de variable _target_: `sentimiento`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri-gHxW2i0Ux"
   },
   "source": [
    "Una vez que comprobamos que está todo OK, agregamos la columna sentimiento y procedemos a exportar los tweets a un .csv para preservar la muestra. Usamos como separador el `;` para que cuando lo abramos en Excel se divida automáticamente en columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TYx24G4i0VV"
   },
   "source": [
    "Crearemos la variable target para, posteriormente, poder realizar la clasificación. Por el momento estará vacía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NPFpsdci0VV"
   },
   "outputs": [],
   "source": [
    "df['sentimiento'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos el dataset crudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos el dataset para combinarlo más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbzj-1Oei0Ux"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/Crudos/tweets_crudos_\"+str(time.time())+\".csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJmK_CS0i0VW"
   },
   "source": [
    "# Limpieza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6Du5tSj0o9W"
   },
   "source": [
    "Tamaño del dataset previo a la limpieza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8RpNdRCT0OwP",
    "outputId": "ef50c236-803f-4595-ac34-1506ae8ad935"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-633337079cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bzOrOstqi0VX"
   },
   "source": [
    "### Por usuarios específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dMmn0api0VX"
   },
   "source": [
    "#### Trolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "ZVtyJh0xi0VX",
    "outputId": "d00c79be-cbed-4d6a-d828-a47cfbaa5335"
   },
   "outputs": [],
   "source": [
    "mask_bl = [x in usuarios_blacklist for x in df['username']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "5gVJZLXDi0VZ",
    "outputId": "f1d50e32-c64f-4085-bf69-ba5be9db8e70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definimos una máscara para excluir a los usuarios en la lista negra\n",
    "mask_not_bl = [x not in usuarios_blacklist for x in df['username']] \n",
    "#pisamos el dataframe sin los usuarios de la lista negra\n",
    "df = df[mask_not_bl]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDySKcJEi0Vb"
   },
   "source": [
    "#### Medios de comunicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lNtAHyb0i0Vb",
    "outputId": "14abea2f-525c-4958-9f2b-76a60123f345"
   },
   "outputs": [],
   "source": [
    "mask_media = [x in usuarios_medios for x in df['username']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVSoatJli0Vc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definimos una máscara para excluir a los usuarios en la lista negra\n",
    "mask_not_media = [x not in usuarios_medios for x in df['username']] \n",
    "#pisamos el dataframe sin los usuarios de la lista negra\n",
    "df = df[mask_not_media]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por contenido de tweets.\n",
    "#### Duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['tweet'], keep=False, inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tópicos no relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>id</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [username, tweet, fecha, anuncio, ubicacion, id, sentimiento]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_topics = [x in topicos_excluidos for x in df['tweet']] \n",
    "df[mask_topics].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_not_topics = [x not in topicos_excluidos for x in df['tweet']] \n",
    "df = df[mask_not_topics]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos el dataset filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/Crudos/tweets_crudos_limpios_\"+str(time.time())+\".csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge de datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de sumar la mayor cantidad de tweets, es necesario que vayamos armando el dataframe consolidado con los datos que vamos obteniendo de \"a cachos\".\n",
    "\n",
    "Por esta razón, tenemos tres datasets:\n",
    "1. Nuevos tweets obtenidos sin clasificar.\n",
    "2. Tweets clasificados.\n",
    "3. Dataframe ya consolidado con todos los tweets obtenidos hasta el momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets con archivo consolidado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_of_files = glob.glob('Data/Consolidado/*.csv') \n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    df_consolidado_nuevo = pd.read_csv(latest_file, sep=';')\n",
    "except:\n",
    "    print(\"No hay archivos en el directorio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.240776e+18</td>\n",
       "      <td>Elizabeth789741</td>\n",
       "      <td>alferdez alferdezprensa por favor qxsea a part...</td>\n",
       "      <td>2020-03-19 23:04:48+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.243993e+18</td>\n",
       "      <td>sergistack</td>\n",
       "      <td>usas google chrome lo siento por las mayuscula...</td>\n",
       "      <td>2020-03-28 20:07:18+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.240774e+18</td>\n",
       "      <td>vickyuliyapo</td>\n",
       "      <td>comodice inesazpelicueta que comiencen ya a el...</td>\n",
       "      <td>2020-03-19 22:57:33+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.240737e+18</td>\n",
       "      <td>RUCHOCASLA</td>\n",
       "      <td>alferdez alferdezprensa a los que enganchan en...</td>\n",
       "      <td>2020-03-19 20:28:12+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.240696e+18</td>\n",
       "      <td>Populismomata</td>\n",
       "      <td>alferdezprensa porque no hacen que el indek mi...</td>\n",
       "      <td>2020-03-19 17:46:55+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id         username  \\\n",
       "0      0  1.240776e+18  Elizabeth789741   \n",
       "1      1  1.243993e+18       sergistack   \n",
       "2      2  1.240774e+18     vickyuliyapo   \n",
       "3      3  1.240737e+18       RUCHOCASLA   \n",
       "4      4  1.240696e+18    Populismomata   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  alferdez alferdezprensa por favor qxsea a part...   \n",
       "1  usas google chrome lo siento por las mayuscula...   \n",
       "2  comodice inesazpelicueta que comiencen ya a el...   \n",
       "3  alferdez alferdezprensa a los que enganchan en...   \n",
       "4  alferdezprensa porque no hacen que el indek mi...   \n",
       "\n",
       "                       fecha    anuncio                ubicacion sentimiento  \n",
       "0  2020-03-19 23:04:48+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  \n",
       "1  2020-03-28 20:07:18+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  \n",
       "2  2020-03-19 22:57:33+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  \n",
       "3  2020-03-19 20:28:12+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  \n",
       "4  2020-03-19 17:46:55+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidado_nuevo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existe la columna fecha_sola\n",
      "(4731, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.240776e+18</td>\n",
       "      <td>Elizabeth789741</td>\n",
       "      <td>alferdez alferdezprensa por favor qxsea a part...</td>\n",
       "      <td>2020-03-19 23:04:48+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.240774e+18</td>\n",
       "      <td>vickyuliyapo</td>\n",
       "      <td>comodice inesazpelicueta que comiencen ya a el...</td>\n",
       "      <td>2020-03-19 22:57:33+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.240737e+18</td>\n",
       "      <td>RUCHOCASLA</td>\n",
       "      <td>alferdez alferdezprensa a los que enganchan en...</td>\n",
       "      <td>2020-03-19 20:28:12+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         username  \\\n",
       "0  1.240776e+18  Elizabeth789741   \n",
       "2  1.240774e+18     vickyuliyapo   \n",
       "3  1.240737e+18       RUCHOCASLA   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  alferdez alferdezprensa por favor qxsea a part...   \n",
       "2  comodice inesazpelicueta que comiencen ya a el...   \n",
       "3  alferdez alferdezprensa a los que enganchan en...   \n",
       "\n",
       "                       fecha    anuncio                ubicacion sentimiento  \n",
       "0  2020-03-19 23:04:48+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  \n",
       "2  2020-03-19 22:57:33+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  \n",
       "3  2020-03-19 20:28:12+00:00  Anuncio_1  Buenos Aires, Argentina         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidado = clean_up_df(df_consolidado_nuevo)\n",
    "print(df_consolidado.shape)\n",
    "df_consolidado.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets con archivos sin clasificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos todos los archivos crudos limpios y los conformamos en un único dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9183, 8)\n"
     ]
    }
   ],
   "source": [
    "path_crudos = 'Data/Crudos/' \n",
    "all_files_crudos = glob.glob(path_crudos + \"/*.csv\")\n",
    "\n",
    "li_crudos = []\n",
    "\n",
    "try:\n",
    "    for filename in all_files_crudos:\n",
    "        df_sin_clasificar = pd.read_csv(filename, sep = ';', header=0)\n",
    "        li_crudos.append(df_sin_clasificar)\n",
    "    concatenado = pd.concat(li_crudos, axis=0) \n",
    "    df_sin_clasificar = concatenado.drop_duplicates()\n",
    "    print(df_sin_clasificar.shape)\n",
    "except:\n",
    "    print(\"No hay archivos en el directorio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9183, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>id</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>fecha_sola</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elizabeth789741</td>\n",
       "      <td>alferdez alferdezprensa por favor qxsea a part...</td>\n",
       "      <td>2020-03-19 23:04:48+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>1.240776e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sergistack</td>\n",
       "      <td>usas google chrome lo siento por las mayuscula...</td>\n",
       "      <td>2020-03-28 20:07:18+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>1.243993e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vickyuliyapo</td>\n",
       "      <td>comodice inesazpelicueta que comiencen ya a el...</td>\n",
       "      <td>2020-03-19 22:57:33+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>1.240774e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                                              tweet  \\\n",
       "0  Elizabeth789741  alferdez alferdezprensa por favor qxsea a part...   \n",
       "1       sergistack  usas google chrome lo siento por las mayuscula...   \n",
       "2     vickyuliyapo  comodice inesazpelicueta que comiencen ya a el...   \n",
       "\n",
       "                       fecha    anuncio                ubicacion  \\\n",
       "0  2020-03-19 23:04:48+00:00  Anuncio_1  Buenos Aires, Argentina   \n",
       "1  2020-03-28 20:07:18+00:00  Anuncio_1  Buenos Aires, Argentina   \n",
       "2  2020-03-19 22:57:33+00:00  Anuncio_1  Buenos Aires, Argentina   \n",
       "\n",
       "             id  sentimiento fecha_sola  \n",
       "0  1.240776e+18          NaN        NaN  \n",
       "1  1.243993e+18          NaN        NaN  \n",
       "2  1.240774e+18          NaN        NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_sin_clasificar.shape)\n",
    "df_sin_clasificar.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset con tweets clasificados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos todos los archivos con tweets clasificados y los conformamos en un único dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Clasificados\\2da_mitad_tweets_clasificados_euge.csv\n",
      "Data/Clasificados\\usuarios_mas_10_tweets_clasificados.csv\n",
      "(3269, 8)\n"
     ]
    }
   ],
   "source": [
    "path_clasificados = 'Data/Clasificados/' \n",
    "all_files_clasificados = glob.glob(path_clasificados + \"/*.csv\")\n",
    "\n",
    "li_clasificados = []\n",
    "\n",
    "try:\n",
    "    for filename in all_files_clasificados:\n",
    "        df_clasificados = pd.read_csv(filename, sep = ';', header=0)\n",
    "        li_clasificados.append(df_clasificados)\n",
    "        print(filename)\n",
    "    concatenado = pd.concat(li_clasificados, axis=0) \n",
    "    df_clasificados = concatenado.drop_duplicates()\n",
    "    print(df_clasificados.shape)\n",
    "except:\n",
    "    print(\"No hay archivos en el directorio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3269, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>fecha_sola</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mar-14</td>\n",
       "      <td>edufeiok edufeiok te comento tengo a mi hijo c...</td>\n",
       "      <td>2020-07-31 21:27:55+00:00</td>\n",
       "      <td>Anuncio_10</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>31-07-20</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>____Marcos77</td>\n",
       "      <td>aguante el coronavirus</td>\n",
       "      <td>2020-08-14 00:30:36+00:00</td>\n",
       "      <td>Anuncio_11</td>\n",
       "      <td>Cordoba, Argentina</td>\n",
       "      <td>14-08-20</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__Maxi94</td>\n",
       "      <td>mamita pique ni el coronavirus se agarra porqu...</td>\n",
       "      <td>2020-08-14 19:23:55+00:00</td>\n",
       "      <td>Anuncio_11</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>14-08-20</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       username                                              tweet  \\\n",
       "0        Mar-14  edufeiok edufeiok te comento tengo a mi hijo c...   \n",
       "1  ____Marcos77                             aguante el coronavirus   \n",
       "2      __Maxi94  mamita pique ni el coronavirus se agarra porqu...   \n",
       "\n",
       "                       fecha     anuncio                ubicacion fecha_sola  \\\n",
       "0  2020-07-31 21:27:55+00:00  Anuncio_10  Buenos Aires, Argentina   31-07-20   \n",
       "1  2020-08-14 00:30:36+00:00  Anuncio_11       Cordoba, Argentina   14-08-20   \n",
       "2  2020-08-14 19:23:55+00:00  Anuncio_11  Buenos Aires, Argentina   14-08-20   \n",
       "\n",
       "  sentimiento  id  \n",
       "0     Neutral NaN  \n",
       "1     Neutral NaN  \n",
       "2     Neutral NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_clasificados.shape)\n",
    "df_clasificados.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     1343\n",
       "Positivo     277\n",
       "Negativo     201\n",
       "Name: sentimiento, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clasificados.sentimiento.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge entre dataset clasificado y sin clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets clasificados en el dataset consolidado, previo al merge: 705\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de tweets clasificados en el dataset consolidado, previo al merge:', df_consolidado.sentimiento.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets clasificados en el dataset sin clasificar, previo al merge: 0\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de tweets clasificados en el dataset sin clasificar, previo al merge:', df_sin_clasificar.sentimiento.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets clasificados en el dataset clasificados, previo al merge: 1821\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de tweets clasificados en el dataset clasificados, previo al merge:', df_clasificados.sentimiento.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12452, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>fecha</th>\n",
       "      <th>anuncio</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>id</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>fecha_sola</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elizabeth789741</td>\n",
       "      <td>alferdez alferdezprensa por favor qxsea a part...</td>\n",
       "      <td>2020-03-19 23:04:48+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>1.240776e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sergistack</td>\n",
       "      <td>usas google chrome lo siento por las mayuscula...</td>\n",
       "      <td>2020-03-28 20:07:18+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>1.243993e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vickyuliyapo</td>\n",
       "      <td>comodice inesazpelicueta que comiencen ya a el...</td>\n",
       "      <td>2020-03-19 22:57:33+00:00</td>\n",
       "      <td>Anuncio_1</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>1.240774e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                                              tweet  \\\n",
       "0  Elizabeth789741  alferdez alferdezprensa por favor qxsea a part...   \n",
       "1       sergistack  usas google chrome lo siento por las mayuscula...   \n",
       "2     vickyuliyapo  comodice inesazpelicueta que comiencen ya a el...   \n",
       "\n",
       "                       fecha    anuncio                ubicacion  \\\n",
       "0  2020-03-19 23:04:48+00:00  Anuncio_1  Buenos Aires, Argentina   \n",
       "1  2020-03-28 20:07:18+00:00  Anuncio_1  Buenos Aires, Argentina   \n",
       "2  2020-03-19 22:57:33+00:00  Anuncio_1  Buenos Aires, Argentina   \n",
       "\n",
       "             id sentimiento fecha_sola  \n",
       "0  1.240776e+18         NaN        NaN  \n",
       "1  1.243993e+18         NaN        NaN  \n",
       "2  1.240774e+18         NaN        NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_appended = df_sin_clasificar.append(df_clasificados)\n",
    "print(df_appended.shape)\n",
    "df_appended.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12452, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidado = df_appended.drop_duplicates()\n",
    "df_consolidado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.907000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.264274e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.957707e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.213622e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.244323e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.264202e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.284191e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.298322e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count  9.907000e+03\n",
       "mean   1.264274e+18\n",
       "std    1.957707e+16\n",
       "min    1.213622e+18\n",
       "25%    1.244323e+18\n",
       "50%    1.264202e+18\n",
       "75%    1.284191e+18\n",
       "max    1.298322e+18"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidado.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos a cuántos tweets se les impactó el valor de `sentimiento`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets clasificados en el dataset, luego del merge: 1821\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de tweets clasificados en el dataset, luego del merge:', df_consolidado.sentimiento.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     1343\n",
       "Positivo     277\n",
       "Negativo     201\n",
       "Name: sentimiento, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidado.sentimiento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12452, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_consolidado\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export del dataset consolidado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También exportaremos el dataset para preservarlo y continuar con las clasificaciones faltantes a través del método \"Mechanical Turk\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)\n",
    "df.to_csv(\"Data/Consolidado/tweets_consolidados_\"+str(time.time())+\".csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export del dataset sin clasificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También exportaremos el dataset de los que quedan sin clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_clasificar = df[(df.sentimiento.isna()) | (df.sentimiento == '')]\n",
    "df_sin_clasificar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qfilas = df_sin_clasificar.shape[0]\n",
    "qfilas = int(round(qfilas / 2, 0))\n",
    "\n",
    "segunda_mitad = df_sin_clasificar.iloc[qfilas:]\n",
    "primera_mitad = df_sin_clasificar.iloc[:qfilas]\n",
    "\n",
    "primera_mitad.shape, segunda_mitad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_mitad_1 = \"1ra_mitad_tweets_sin_clasificar.csv\"\n",
    "nombre_mitad_2 = \"2da_mitad_tweets_sin_clasificar.csv\"\n",
    "\n",
    "ruta_drive_mitad_1 = \"/content/drive/My Drive/TP Integrador/Notebooks/Data/\"+nombre_mitad_1\n",
    "ruta_drive_mitad_2 = \"/content/drive/My Drive/TP Integrador/Notebooks/Data/\"+nombre_mitad_2\n",
    "ruta_local_mitad_1 = \"Data/\"+nombre_mitad_1\n",
    "ruta_local_mitad_2 = \"Data/\"+nombre_mitad_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    primera_mitad.to_csv(ruta_drive_mitad_1, sep=';', index=False)\n",
    "    segunda_mitad.to_csv(ruta_drive_mitad_2, sep=';', index=False)\n",
    "except:\n",
    "    primera_mitad.to_csv(ruta_local_mitad_1, sep=';', index=False)\n",
    "    segunda_mitad.to_csv(ruta_local_mitad_2, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibGXEx93i0U3"
   },
   "source": [
    "# EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zV5lCd0ni0U4"
   },
   "source": [
    "## Revisando la forma del Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_up_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "PpXSnNmui0U4",
    "outputId": "059b4f0d-8b76-49ec-a3c7-b014f860d3d7"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FmKOSDbti0U6",
    "outputId": "307a61fe-4d73-41ca-9545-8d01bb981092"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "Wgvg2Ah1i0U8",
    "outputId": "bd5d509a-07e6-468b-9834-a0b57fd79aec"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "EdEeeXsKi0U-",
    "outputId": "9b9ba098-a40e-477b-aeef-d4dfb2e359b9"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sr3Ey1ppi0VA"
   },
   "source": [
    "## Análisis de _features_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBYwcfQ9i0VA"
   },
   "source": [
    "### Valores de `username`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "DAQ7cC4zi0VA",
    "outputId": "51d44eeb-eee4-4267-c5aa-fff6462845cd"
   },
   "outputs": [],
   "source": [
    "print(df.username.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "id": "Q0Ie4zqPi0VC",
    "outputId": "0e7f38ec-bc9c-49f0-83fb-3da14d7e4727"
   },
   "outputs": [],
   "source": [
    "#usuarios_mas_10_tweets = df['username'].isin(df['username'].value_counts()[df['username'].value_counts()> 10].index)\n",
    "#df[usuarios_mas_10_tweets].username.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLaRwB7Ei0VD"
   },
   "source": [
    "### Valores de `anuncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "iE9wUiLXi0VE",
    "outputId": "181e170a-1290-48a6-e097-0aebd558af01"
   },
   "outputs": [],
   "source": [
    "print(df.anuncio.value_counts())\n",
    "plt.title('Distribución de anuncio')\n",
    "df.anuncio.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZS5cNb4i0VF"
   },
   "source": [
    "### Valores de `ubicacion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "5mmLRIWdi0VG",
    "outputId": "3b9d5180-8ed5-4dfc-9918-cba610390d4e"
   },
   "outputs": [],
   "source": [
    "print(df.ubicacion.value_counts())\n",
    "plt.title('Distribución de ubicacion')\n",
    "df.ubicacion.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYwQ8AUai0VH"
   },
   "source": [
    "### Valores de `fecha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "nrcfbja6i0VT",
    "outputId": "d6d58830-33b1-4abe-fa82-4aadfefe0be9"
   },
   "outputs": [],
   "source": [
    "print(df['fecha'].map(lambda x: str(x)[:-15]).value_counts())\n",
    "plt.title('Distribución de fechas')\n",
    "df['fecha'].map(lambda x: str(x)[:-15]).value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPdcQJ7Ci0VJ"
   },
   "source": [
    "Para poder aprovechar las funcionalidades después, es conveniente convertir el campo \"fecha\" en timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsqKRaGMi0VK"
   },
   "outputs": [],
   "source": [
    "df['fecha'] = pd.to_datetime(df['fecha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zg9_vbD9i0VP"
   },
   "source": [
    "### Valores de `tweet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5-HFwDDi0VP"
   },
   "source": [
    "Procedemos a chusmear los valores de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "h3rGG1R2i0VQ",
    "outputId": "ccb3a036-3589-46fa-bd6d-722e36105929"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edhQcyw4i0Vm"
   },
   "source": [
    "Ahora sí... ¡a trabajar en el modelo!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1. Cuarentena Tweets - Dataset y EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
